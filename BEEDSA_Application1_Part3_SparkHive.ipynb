{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create SparkContext, SparkSession\n",
    "from os.path import expanduser, join, abspath\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# warehouse_location points to the default location for managed databases and tables\n",
    "warehouse_location = 'hdfs:///apps/hive/warehouse/'\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL Hive integration example\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Use hive database which you have created\n",
    "spark.sql(\"use insofe_b43_g6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-----------+\n",
      "|     database|   tableName|isTemporary|\n",
      "+-------------+------------+-----------+\n",
      "|insofe_b43_g6| departments|      false|\n",
      "|insofe_b43_g6|    dept_emp|      false|\n",
      "|insofe_b43_g6|dept_manager|      false|\n",
      "|insofe_b43_g6|   employees|      false|\n",
      "|insofe_b43_g6|    salaries|      false|\n",
      "|insofe_b43_g6|      titles|      false|\n",
      "+-------------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deptDF = spark.sql(\"SELECT * FROM departments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+\n",
      "|dept_no|         dept_name|      last_modified|\n",
      "+-------+------------------+-------------------+\n",
      "|   d001|         Marketing|2013-01-28 23:59:59|\n",
      "|   d002|           Finance|2013-01-28 23:59:59|\n",
      "|   d003|   Human Resources|2013-01-28 23:59:59|\n",
      "|   d004|        Production|2013-01-28 23:59:59|\n",
      "|   d005|       Development|2013-01-28 23:59:59|\n",
      "|   d006|Quality Management|2013-01-28 23:59:59|\n",
      "|   d007|             Sales|2013-01-28 23:59:59|\n",
      "|   d008|          Research|2013-01-28 23:59:59|\n",
      "|   d009|  Customer Service|2013-01-28 23:59:59|\n",
      "|   d010|         Analytics|2018-08-18 12:38:38|\n",
      "+-------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deptDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+----------+----------+-------------------+\n",
      "|seq_no|emp_no|dept_no| from_date|   to_date|      last_modified|\n",
      "+------+------+-------+----------+----------+-------------------+\n",
      "|     1|     1|   d001|1986-01-01|9999-01-01|2013-01-28 23:59:59|\n",
      "|    10|    10|   d002|1986-01-14|9999-01-01|2013-01-28 23:59:59|\n",
      "+------+------+-------+----------+----------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_empDF = spark.sql(\"SELECT * FROM dept_emp\")\n",
    "dept_empDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+-------------------+\n",
      "|seq_no|dept_no|emp_no| from_date|   to_date|      last_modified|\n",
      "+------+-------+------+----------+----------+-------------------+\n",
      "|     1|   d001|     1|1986-01-01|1992-10-01|2013-01-28 23:59:59|\n",
      "|    10|   d002|    10|1990-12-17|9999-01-01|2013-01-28 23:59:59|\n",
      "+------+-------+------+----------+----------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_managerDF = spark.sql(\"SELECT * FROM dept_manager\")\n",
    "dept_managerDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+----------+------+----------+-------------------+\n",
      "|emp_no|birth_date|first_name| last_name|gender| hire_date|      last_modified|\n",
      "+------+----------+----------+----------+------+----------+-------------------+\n",
      "|     1|1958-09-12| Margareta|Markovitch|     M|1986-01-01|2013-01-28 23:59:59|\n",
      "|     2|1961-10-28|      Ebru|     Alpin|     M|1986-01-01|2013-01-28 23:59:59|\n",
      "+------+----------+----------+----------+------+----------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF = spark.sql(\"SELECT * FROM employees\")\n",
    "employeesDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+----------+----------+-------------------+\n",
      "|seq_no|emp_no|salary| from_date|   to_date|      last_modified|\n",
      "+------+------+------+----------+----------+-------------------+\n",
      "|     1|     1| 70166|1986-01-01|1987-01-01|2013-01-28 23:59:59|\n",
      "|    10|     1| 91165|1994-12-30|1995-12-30|2013-01-28 23:59:59|\n",
      "+------+------+------+----------+----------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salariesDF = spark.sql(\"SELECT * FROM salaries\")\n",
    "salariesDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------------+----------+----------+-------------------+\n",
      "|seq_no|emp_no|           title| from_date|   to_date|      last_modified|\n",
      "+------+------+----------------+----------+----------+-------------------+\n",
      "|     1|     1|         Manager|1986-01-01|1992-10-01|2013-01-28 23:59:59|\n",
      "|    10|     5|Technique Leader|1993-04-25|9999-01-01|2013-01-28 23:59:59|\n",
      "+------+------+----------------+----------+----------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titlesDF = spark.sql(\"SELECT * FROM titles\")\n",
    "titlesDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+----------+---------+------+---------------+----------+------+----------+----------+-------------------+\n",
      "|emp_no|dept_no|birth_date|first_name|last_name|gender|          title| hire_date|salary| from_date|   to_date|      last_modified|\n",
      "+------+-------+----------+----------+---------+------+---------------+----------+------+----------+----------+-------------------+\n",
      "|   148|   d005|1960-03-11|    Feipei| Nollmann|     M|Senior Engineer|1986-02-03|121640|1986-02-03|9999-01-01|2013-01-28 23:59:59|\n",
      "+------+-------+----------+----------+---------+------+---------------+----------+------+----------+----------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF = spark.sql(\"select e.emp_no,de.dept_no,e.birth_date,e.first_name,e.last_name,e.gender, \\\n",
    "               t.title,e.hire_date,s.salary,de.from_date,de.to_date,de.last_modified, \\\n",
    "               from  employees e inner join dept_emp de on e.emp_no=de.emp_no \\\n",
    "               inner join titles t on e.emp_no=t.emp_no \\\n",
    "               inner join salaries s on e.emp_no=s.emp_no \\\n",
    "               where de.to_date ='9999-01-01' and t.to_date='9999-01-01' and s.to_date='9999-01-01' \").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  250124|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF1 = spark.sql(\"select count(*) \\\n",
    "               from  employees e inner join dept_emp de on e.emp_no=de.emp_no \\+\n",
    "               inner join titles t on e.emp_no=t.emp_no \\\n",
    "               inner join salaries s on e.emp_no=s.emp_no \\\n",
    "              where de.to_date ='9999-01-01' and t.to_date='9999-01-01' and s.to_date='9999-01-01' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  250124|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  250124|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  250124|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ActiveEmp = spark.sql(\"select count(*) from  dept_emp e  where e.to_date ='9999-01-01' \").show()\n",
    "ActiveTitles = spark.sql(\"select count(*) from  titles t  where t.to_date ='9999-01-01' \").show()\n",
    "ActiveSal = spark.sql(\"select count(*) from  salaries s  where s.to_date ='9999-01-01' \").show()\n",
    "#DFQ1 = spark.sql(\"select datediff(dw,birth_date,getdate),datediff(dw,hire_date,getdate) from \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+----------+---------+------+---------------+----------+------+----------+----------+-------------------+---------+---------+\n",
      "|emp_no|dept_no|birth_date|first_name|last_name|gender|          title| hire_date|salary| from_date|   to_date|      last_modified|      age|   tenure|\n",
      "+------+-------+----------+----------+---------+------+---------------+----------+------+----------+----------+-------------------+---------+---------+\n",
      "|   148|   d005|1960-03-11|    Feipei| Nollmann|     M|Senior Engineer|1986-02-03|121640|1986-02-03|9999-01-01|2013-01-28 23:59:59|58.436687|32.536619|\n",
      "+------+-------+----------+----------+---------+------+---------------+----------+------+----------+----------+-------------------+---------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF2 = spark.sql(\"select e.emp_no,de.dept_no,e.birth_date,e.first_name,e.last_name,e.gender, \\\n",
    "               t.title,e.hire_date,s.salary,de.from_date,de.to_date,de.last_modified,datediff(now(),birth_date)/365.25 as age, \\\n",
    "               datediff(now(),hire_date)/365.25 as tenure \\\n",
    "                from  employees e inner join dept_emp de on e.emp_no=de.emp_no \\\n",
    "               inner join titles t on e.emp_no=t.emp_no \\\n",
    "               inner join salaries s on e.emp_no=s.emp_no \\\n",
    "               where de.to_date ='9999-01-01' and t.to_date='9999-01-01' and s.to_date='9999-01-01' \").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
