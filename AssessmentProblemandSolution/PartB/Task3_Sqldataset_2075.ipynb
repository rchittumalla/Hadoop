{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"]=\"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"]=os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0,os.environ[\"PYLIB\"] + \"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0,os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create SparkContext ,Sparksession\n",
    "from os.path import expanduser,join,abspath\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "#warehouse location points to the default location for managed databases and tables.\n",
    "warehouse_location = 'hdfs:///apps/hive/warehouse/'\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL Hive integration example\").config(\"spark.sql.warehouse.dir\",warehouse_location).enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://s.insofe.edu.in:4048\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.2.6.5.0-292</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Python Spark SQL Hive integration example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2a1acd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "#Read data and create a dataframe\n",
    "data = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .option(\"mode\", \"DROPMALFORMED\")\\\n",
    "        .load(\"file:///home/2075B43/Task3/SQL_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+--------------------+--------------------+--------------------+------------------+---------------+----+--------------------+-----------+----------+\n",
      "|ROW_ID|        CASE_STATUS|       EMPLOYER_NAME|            SOC_NAME|           JOB_TITLE|FULL_TIME_POSITION|PREVAILING_WAGE|YEAR|            WORKSITE|        lon|       lat|\n",
      "+------+-------------------+--------------------+--------------------+--------------------+------------------+---------------+----+--------------------+-----------+----------+\n",
      "|     1|CERTIFIED-WITHDRAWN|UNIVERSITY OF MIC...|BIOCHEMISTS AND B...|POSTDOCTORAL RESE...|                 N|          36067|2016| ANN ARBOR, MICHIGAN|-83.7430378|42.2808256|\n",
      "|     2|CERTIFIED-WITHDRAWN|GOODMAN NETWORKS,...|    CHIEF EXECUTIVES|CHIEF OPERATING O...|                 Y|         242674|2016|        PLANO, TEXAS|-96.6988856|33.0198431|\n",
      "|     3|CERTIFIED-WITHDRAWN|PORT S AMERICA GR...|    CHIEF EXECUTIVES|CHIEF PROCESS OFF...|                 Y|         193066|2016|JERSEY CITY, NEW ...|-74.0776417|40.7281575|\n",
      "|     4|CERTIFIED-WITHDRAWN|GATES CORPORATION...|    CHIEF EXECUTIVES|REGIONAL PRESIDEN...|                 Y|         220314|2016|    DENVER, COLORADO|-104.990251|39.7392358|\n",
      "|     5|          WITHDRAWN|PEABODY INVESTMEN...|    CHIEF EXECUTIVES|PRESIDENT MONGOLI...|                 Y|       157518.4|2016| ST. LOUIS, MISSOURI|-90.1994042|38.6270025|\n",
      "+------+-------------------+--------------------+--------------------+--------------------+------------------+---------------+----+--------------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records count is 3002425\n",
      "Total Columns count is 11\n"
     ]
    }
   ],
   "source": [
    "#Verify the total rows and columns\n",
    "## To Count the number of rows in DataFrame\n",
    "print('Total records count is {}'.format(data.count()))\n",
    "## Columns count and column names\n",
    "print(\"Total Columns count is {}\".format(len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records count is 3002458\n",
      "Total Columns count is 11\n"
     ]
    }
   ],
   "source": [
    "#Verify the total rows and columns\n",
    "## To Count the number of rows in DataFrame\n",
    "print('Total records count is {}'.format(data.count()))\n",
    "## Columns count and column names\n",
    "print(\"Total Columns count is {}\".format(len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------+--------------------+--------------------+--------------------+------------------+------------------+------------------+--------------------+------------------+------------------+\n",
      "|summary|            ROW_ID|CASE_STATUS|       EMPLOYER_NAME|            SOC_NAME|           JOB_TITLE|FULL_TIME_POSITION|   PREVAILING_WAGE|              YEAR|            WORKSITE|               lon|               lat|\n",
      "+-------+------------------+-----------+--------------------+--------------------+--------------------+------------------+------------------+------------------+--------------------+------------------+------------------+\n",
      "|  count|           3002425|    3002425|             3002425|             3002425|             3002425|           3002425|           3002425|           3002425|             3002425|           3002425|           3002425|\n",
      "|   mean|1501224.9845368327|       null|       3.218588665E8|                null|           238095.35|              null|146999.33453811772|2013.8550268917124|                null|-92.13453247915034|38.160543835567715|\n",
      "| stddev| 866736.0571603886|       null|2.2409937148797384E8|                null|  2011997.0630112377|              null| 5287638.497410159| 1.680614066178571|                null|19.655939595322643| 4.672829081871288|\n",
      "|    min|                 1|  CERTIFIED|\"\"\"EXCELLENT COMP...|          13-2011.01|\"\"\"BUSINESS SYSTE...|                 N|                 0|              2011|# 19100 DIV CD 19...|      -100.3509665|        13.4371922|\n",
      "|    max|           3002458|  WITHDRAWN|        ËNIMAI, INC.|Zoologists and Wi...|   TEST ANALYST - US|                 Y|                NA|                NA| FORT WASHINGTON,...|                NA|                NA|\n",
      "+-------+------------------+-----------+--------------------+--------------------+--------------------+------------------+------------------+------------------+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------+--------+---------+------------------+---------------+----+--------+----+----+\n",
      "| ROW_ID|CASE_STATUS|EMPLOYER_NAME|SOC_NAME|JOB_TITLE|FULL_TIME_POSITION|PREVAILING_WAGE|YEAR|WORKSITE| lon| lat|\n",
      "+-------+-----------+-------------+--------+---------+------------------+---------------+----+--------+----+----+\n",
      "|3002458|          8|       236016|    2140|   287560|                25|          56161|  33|   18633|2423|2416|\n",
      "+-------+-----------+-------------+--------+---------+------------------+---------------+----+--------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Find the Distinct values count in each column\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "data.agg(*(countDistinct(col(c)).alias(c) for c in data.columns)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create view/table\n",
    "data.createOrReplaceTempView(\"SqlTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List EMPLOYER_NAME and YEAR in the descending order\n",
    "Filter1 = spark.sql(\"\"\"SELECT EMPLOYER_NAME, YEAR,CASE_STATUS  FROM SqlTable WHERE CASE_STATUS='CERTIFIED' ORDER BY CASE_STATUS desc\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----------+\n",
      "|       EMPLOYER_NAME|YEAR|CASE_STATUS|\n",
      "+--------------------+----+-----------+\n",
      "|       ACCENTURE LLP|2011|  CERTIFIED|\n",
      "|WILLIAM CAREY UNI...|2011|  CERTIFIED|\n",
      "|EXILANT CONSULTIN...|2011|  CERTIFIED|\n",
      "|QUALCOMM INCORPOR...|2011|  CERTIFIED|\n",
      "|NFL ENTERPRISES,LLC.|2011|  CERTIFIED|\n",
      "+--------------------+----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Filter1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the approved applications count in the descending order for the JOB_TITLE = \"DATA SCIENTIST\" and for each employer and year\n",
    "Filter2 = spark.sql(\"\"\"\n",
    "SELECT EMPLOYER_NAME, YEAR,CASE_STATUS,JOB_TITLE  FROM SqlTable WHERE CASE_STATUS='CERTIFIED' and JOB_TITLE='DATA SCIENTIST' ORDER BY CASE_STATUS desc\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+-----------+--------------+\n",
      "|     EMPLOYER_NAME|YEAR|CASE_STATUS|     JOB_TITLE|\n",
      "+------------------+----+-----------+--------------+\n",
      "|        IMVU, INC.|2011|  CERTIFIED|DATA SCIENTIST|\n",
      "|INTENT MEDIA, INC.|2011|  CERTIFIED|DATA SCIENTIST|\n",
      "|    FACEBOOK, INC.|2011|  CERTIFIED|DATA SCIENTIST|\n",
      "|       INTUIT INC.|2011|  CERTIFIED|DATA SCIENTIST|\n",
      "|   KONTAGENT, INC.|2011|  CERTIFIED|DATA SCIENTIST|\n",
      "+------------------+----+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Filter2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------------+--------+---------+------------------+---------------+----+--------+---+---+\n",
      "|ROW_ID|CASE_STATUS|EMPLOYER_NAME|SOC_NAME|JOB_TITLE|FULL_TIME_POSITION|PREVAILING_WAGE|YEAR|WORKSITE|lon|lat|\n",
      "+------+-----------+-------------+--------+---------+------------------+---------------+----+--------+---+---+\n",
      "|     0|          0|            0|       0|        0|                 0|              0|   0|       0|  0|  0|\n",
      "+------+-----------+-------------+--------+---------+------------------+---------------+----+--------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verify for Null Values\n",
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in raw_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Before Dropping Null Values', 3002425)\n",
      "('After Dropping Null Values', 3002425)\n"
     ]
    }
   ],
   "source": [
    "# Remove all the rows with null values (in any column/position). \n",
    "df = data.na.drop( how = 'any' )\n",
    "print('Before Dropping Null Values', data.count())\n",
    "print('After Dropping Null Values', df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------------+--------+---------+------------------+---------------+----+--------+---+---+\n",
      "|ROW_ID|CASE_STATUS|EMPLOYER_NAME|SOC_NAME|JOB_TITLE|FULL_TIME_POSITION|PREVAILING_WAGE|YEAR|WORKSITE|lon|lat|\n",
      "+------+-----------+-------------+--------+---------+------------------+---------------+----+--------+---+---+\n",
      "|     0|          0|            0|       0|        0|                 0|              0|   0|       0|  0|  0|\n",
      "+------+-----------+-------------+--------+---------+------------------+---------------+----+--------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verify the null values count in each column. \n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the count of applications in each status (CASE_STATUS) in the descending order of the year. \n",
    "filter3 = spark.sql(\"\"\"SELECT CASE_STATUS,YEAR, count(*)  FROM SqlTable GROUP BY CASE_STATUS,YEAR ORDER BY YEAR\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+--------+\n",
      "|        CASE_STATUS|YEAR|count(1)|\n",
      "+-------------------+----+--------+\n",
      "|             DENIED|2011|   29130|\n",
      "|          CERTIFIED|2011|  307933|\n",
      "|CERTIFIED-WITHDRAWN|2011|   11596|\n",
      "|          WITHDRAWN|2011|   10105|\n",
      "|          CERTIFIED|2012|  352661|\n",
      "+-------------------+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean PREVAILING_WAGE for each year for the approved applications\n",
    "Filter4 = spark.sql(\"\"\"\n",
    "SELECT YEAR,AVG(PREVAILING_WAGE) FROM SqlTable WHERE CASE_STATUS='CERTIFIED' GROUP BY YEAR \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------------------+\n",
      "|YEAR|avg(CAST(PREVAILING_WAGE AS DOUBLE))|\n",
      "+----+------------------------------------+\n",
      "|2016|                   74235.85388256852|\n",
      "|2012|                    70842.5693889056|\n",
      "|2014|                   70573.50438874042|\n",
      "|2013|                   71712.24635279125|\n",
      "|2011|                   75453.04075967995|\n",
      "+----+------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Filter4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean PREVAILING_WAGE for each year for the approved applications for each employer. \n",
    "Filter5 = spark.sql(\"\"\"\n",
    "SELECT YEAR,EMPLOYER_NAME,AVG(PREVAILING_WAGE) FROM SqlTable WHERE CASE_STATUS='CERTIFIED' GROUP BY YEAR,EMPLOYER_NAME\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------------------------+\n",
      "|YEAR|       EMPLOYER_NAME|avg(CAST(PREVAILING_WAGE AS DOUBLE))|\n",
      "+----+--------------------+------------------------------------+\n",
      "|2016|  UNDER ARMOUR, INC.|                   89590.66666666667|\n",
      "|2016|ASHLEY HOMESTORES...|                            158038.0|\n",
      "|2016| RODAN & FIELDS, LLC|                          133289.125|\n",
      "|2016|SAATCHI & SAATCHI...|                            122971.5|\n",
      "|2016|GLOBAL ENERGY OPT...|                            117749.0|\n",
      "+----+--------------------+------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Filter5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the approved applications count in each year for the full-time positions in the descending order of the year.\n",
    "Filter6 = spark.sql(\"\"\"SELECT YEAR,FULL_TIME_POSITION,count(CASE_STATUS) FROM SqlTable WHERE CASE_STATUS='CERTIFIED' group by YEAR,FULL_TIME_POSITION  ORDER BY YEAR\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "|YEAR|FULL_TIME_POSITION|count(CASE_STATUS)|\n",
      "+----+------------------+------------------+\n",
      "|2011|                 Y|            295607|\n",
      "|2011|                 N|             12326|\n",
      "|2012|                 N|             12227|\n",
      "|2012|                 Y|            340434|\n",
      "|2013|                 N|             11472|\n",
      "+----+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Filter6.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
